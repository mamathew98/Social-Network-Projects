{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Syntagmatic Relation Network\n",
    "\n",
    "The module developed below extracts syntagmatic relations between word in a corpus and generates\n",
    "nodes and edges for graph visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "0. [Import Libraries](#0)\n",
    "1. [Load Data](#1)\n",
    "2. [Select Required Columns](#2)\n",
    "3. [Pre-Process Text](#3)\n",
    "4. [Create Corpus](#4)\n",
    "5. [Vectorize Word-Doc Relations](#5)\n",
    "6. [Get Occurrence and Co-Occurrence matrix](#6)\n",
    "7. [Function to Find Index of element in np array](#7)\n",
    "8. [Calculate number of documents containing specific word](#9)\n",
    "9. [Functions to produce Mutual Information](#9)\n",
    "10. [Calculate MI score for all pairs of words](#10)\n",
    "11. [Syntagmtatic Related words](#11)\n",
    "12. [Save Output](#12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Libraries <a class=\"anchor\" id=\"0\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from modules.tweetToWords import tweetToWords\n",
    "from dateutil.parser import parse\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "from itertools import combinations\n",
    "from tqdm.contrib import tzip\n",
    "import sys\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1 Load Data <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1698308935</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/169...</td>\n",
       "      <td>Be sure to tune in and watch Donald Trump on L...</td>\n",
       "      <td>2009-05-04 13:54:25</td>\n",
       "      <td>510</td>\n",
       "      <td>917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1701461182</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/170...</td>\n",
       "      <td>Donald Trump will be appearing on The View tom...</td>\n",
       "      <td>2009-05-04 20:00:10</td>\n",
       "      <td>34</td>\n",
       "      <td>267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1737479987</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/173...</td>\n",
       "      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n",
       "      <td>2009-05-08 08:38:08</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1741160716</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/174...</td>\n",
       "      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n",
       "      <td>2009-05-08 15:40:15</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1773561338</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/177...</td>\n",
       "      <td>\"My persona will never be that of a wallflower...</td>\n",
       "      <td>2009-05-12 09:07:28</td>\n",
       "      <td>1375</td>\n",
       "      <td>1945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               link  \\\n",
       "0  1698308935  https://twitter.com/realDonaldTrump/status/169...   \n",
       "1  1701461182  https://twitter.com/realDonaldTrump/status/170...   \n",
       "2  1737479987  https://twitter.com/realDonaldTrump/status/173...   \n",
       "3  1741160716  https://twitter.com/realDonaldTrump/status/174...   \n",
       "4  1773561338  https://twitter.com/realDonaldTrump/status/177...   \n",
       "\n",
       "                                             content                 date  \\\n",
       "0  Be sure to tune in and watch Donald Trump on L...  2009-05-04 13:54:25   \n",
       "1  Donald Trump will be appearing on The View tom...  2009-05-04 20:00:10   \n",
       "2  Donald Trump reads Top Ten Financial Tips on L...  2009-05-08 08:38:08   \n",
       "3  New Blog Post: Celebrity Apprentice Finale and...  2009-05-08 15:40:15   \n",
       "4  \"My persona will never be that of a wallflower...  2009-05-12 09:07:28   \n",
       "\n",
       "   retweets  favorites mentions hashtags  \n",
       "0       510        917      NaN      NaN  \n",
       "1        34        267      NaN      NaN  \n",
       "2        13         19      NaN      NaN  \n",
       "3        11         26      NaN      NaN  \n",
       "4      1375       1945      NaN      NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the csv file\n",
    "csv_file = pd.read_csv('realdonaldtrump.csv')\n",
    "csv_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Select Required Columns <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Be sure to tune in and watch Donald Trump on L...</td>\n",
       "      <td>2009-05-04 13:54:25</td>\n",
       "      <td>510</td>\n",
       "      <td>917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump will be appearing on The View tom...</td>\n",
       "      <td>2009-05-04 20:00:10</td>\n",
       "      <td>34</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n",
       "      <td>2009-05-08 08:38:08</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n",
       "      <td>2009-05-08 15:40:15</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"My persona will never be that of a wallflower...</td>\n",
       "      <td>2009-05-12 09:07:28</td>\n",
       "      <td>1375</td>\n",
       "      <td>1945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content                 date  \\\n",
       "0  Be sure to tune in and watch Donald Trump on L...  2009-05-04 13:54:25   \n",
       "1  Donald Trump will be appearing on The View tom...  2009-05-04 20:00:10   \n",
       "2  Donald Trump reads Top Ten Financial Tips on L...  2009-05-08 08:38:08   \n",
       "3  New Blog Post: Celebrity Apprentice Finale and...  2009-05-08 15:40:15   \n",
       "4  \"My persona will never be that of a wallflower...  2009-05-12 09:07:28   \n",
       "\n",
       "   retweets  favorites  \n",
       "0       510        917  \n",
       "1        34        267  \n",
       "2        13         19  \n",
       "3        11         26  \n",
       "4      1375       1945  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get selected cells from csv\n",
    "data = csv_file[[\"content\", \"date\", \"retweets\", \"favorites\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Pre-Process Text <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43352/43352 [03:34<00:00, 202.48it/s]\n",
      "C:\\Users\\mamat\\AppData\\Local\\Temp/ipykernel_5088/1743885263.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['cleantext']=cleantext\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>cleantext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Be sure to tune in and watch Donald Trump on L...</td>\n",
       "      <td>2009-05-04 13:54:25</td>\n",
       "      <td>510</td>\n",
       "      <td>917</td>\n",
       "      <td>sure tune watch donald trump late night david ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump will be appearing on The View tom...</td>\n",
       "      <td>2009-05-04 20:00:10</td>\n",
       "      <td>34</td>\n",
       "      <td>267</td>\n",
       "      <td>donald trump appearing view tomorrow morning d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n",
       "      <td>2009-05-08 08:38:08</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>donald trump read top ten financial tip late s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n",
       "      <td>2009-05-08 15:40:15</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>new blog post celebrity apprentice finale less...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"My persona will never be that of a wallflower...</td>\n",
       "      <td>2009-05-12 09:07:28</td>\n",
       "      <td>1375</td>\n",
       "      <td>1945</td>\n",
       "      <td>persona never wallflower rather build wall cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43347</th>\n",
       "      <td>Joe Biden was a TOTAL FAILURE in Government. H...</td>\n",
       "      <td>2020-06-17 19:00:32</td>\n",
       "      <td>23402</td>\n",
       "      <td>116377</td>\n",
       "      <td>joe biden total failure government bungled eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43348</th>\n",
       "      <td>Will be interviewed on @ seanhannity tonight a...</td>\n",
       "      <td>2020-06-17 19:11:47</td>\n",
       "      <td>11810</td>\n",
       "      <td>56659</td>\n",
       "      <td>interviewed seanhannity tonight enjoy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43349</th>\n",
       "      <td>pic.twitter.com/3lm1spbU8X</td>\n",
       "      <td>2020-06-17 21:27:33</td>\n",
       "      <td>4959</td>\n",
       "      <td>19344</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43350</th>\n",
       "      <td>pic.twitter.com/vpCE5MadUz</td>\n",
       "      <td>2020-06-17 21:28:38</td>\n",
       "      <td>4627</td>\n",
       "      <td>17022</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43351</th>\n",
       "      <td>pic.twitter.com/VLlc0BHW41</td>\n",
       "      <td>2020-06-17 21:28:52</td>\n",
       "      <td>3951</td>\n",
       "      <td>14344</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43352 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content                 date  \\\n",
       "0      Be sure to tune in and watch Donald Trump on L...  2009-05-04 13:54:25   \n",
       "1      Donald Trump will be appearing on The View tom...  2009-05-04 20:00:10   \n",
       "2      Donald Trump reads Top Ten Financial Tips on L...  2009-05-08 08:38:08   \n",
       "3      New Blog Post: Celebrity Apprentice Finale and...  2009-05-08 15:40:15   \n",
       "4      \"My persona will never be that of a wallflower...  2009-05-12 09:07:28   \n",
       "...                                                  ...                  ...   \n",
       "43347  Joe Biden was a TOTAL FAILURE in Government. H...  2020-06-17 19:00:32   \n",
       "43348  Will be interviewed on @ seanhannity tonight a...  2020-06-17 19:11:47   \n",
       "43349                         pic.twitter.com/3lm1spbU8X  2020-06-17 21:27:33   \n",
       "43350                         pic.twitter.com/vpCE5MadUz  2020-06-17 21:28:38   \n",
       "43351                         pic.twitter.com/VLlc0BHW41  2020-06-17 21:28:52   \n",
       "\n",
       "       retweets  favorites                                          cleantext  \n",
       "0           510        917  sure tune watch donald trump late night david ...  \n",
       "1            34        267  donald trump appearing view tomorrow morning d...  \n",
       "2            13         19  donald trump read top ten financial tip late s...  \n",
       "3            11         26  new blog post celebrity apprentice finale less...  \n",
       "4          1375       1945  persona never wallflower rather build wall cli...  \n",
       "...         ...        ...                                                ...  \n",
       "43347     23402     116377  joe biden total failure government bungled eve...  \n",
       "43348     11810      56659              interviewed seanhannity tonight enjoy  \n",
       "43349      4959      19344                                                     \n",
       "43350      4627      17022                                                     \n",
       "43351      3951      14344                                                     \n",
       "\n",
       "[43352 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleantext=[]\n",
    "for item in tqdm(data['content']):\n",
    "    words=tweetToWords(item)\n",
    "    cleantext+=[words]\n",
    "data['cleantext']=cleantext\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'miss usa tara conner fired always believer second chance say donald trump'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.cleantext[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Date DataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43352/43352 [00:03<00:00, 12987.44it/s]\n",
      "C:\\Users\\mamat\\AppData\\Local\\Temp/ipykernel_5088/2385803758.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['date']=dates\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>cleantext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Be sure to tune in and watch Donald Trump on L...</td>\n",
       "      <td>2009</td>\n",
       "      <td>510</td>\n",
       "      <td>917</td>\n",
       "      <td>sure tune watch donald trump late night david ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump will be appearing on The View tom...</td>\n",
       "      <td>2009</td>\n",
       "      <td>34</td>\n",
       "      <td>267</td>\n",
       "      <td>donald trump appearing view tomorrow morning d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n",
       "      <td>2009</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>donald trump read top ten financial tip late s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n",
       "      <td>2009</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>new blog post celebrity apprentice finale less...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"My persona will never be that of a wallflower...</td>\n",
       "      <td>2009</td>\n",
       "      <td>1375</td>\n",
       "      <td>1945</td>\n",
       "      <td>persona never wallflower rather build wall cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43347</th>\n",
       "      <td>Joe Biden was a TOTAL FAILURE in Government. H...</td>\n",
       "      <td>2020</td>\n",
       "      <td>23402</td>\n",
       "      <td>116377</td>\n",
       "      <td>joe biden total failure government bungled eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43348</th>\n",
       "      <td>Will be interviewed on @ seanhannity tonight a...</td>\n",
       "      <td>2020</td>\n",
       "      <td>11810</td>\n",
       "      <td>56659</td>\n",
       "      <td>interviewed seanhannity tonight enjoy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43349</th>\n",
       "      <td>pic.twitter.com/3lm1spbU8X</td>\n",
       "      <td>2020</td>\n",
       "      <td>4959</td>\n",
       "      <td>19344</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43350</th>\n",
       "      <td>pic.twitter.com/vpCE5MadUz</td>\n",
       "      <td>2020</td>\n",
       "      <td>4627</td>\n",
       "      <td>17022</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43351</th>\n",
       "      <td>pic.twitter.com/VLlc0BHW41</td>\n",
       "      <td>2020</td>\n",
       "      <td>3951</td>\n",
       "      <td>14344</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43352 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  date  retweets  \\\n",
       "0      Be sure to tune in and watch Donald Trump on L...  2009       510   \n",
       "1      Donald Trump will be appearing on The View tom...  2009        34   \n",
       "2      Donald Trump reads Top Ten Financial Tips on L...  2009        13   \n",
       "3      New Blog Post: Celebrity Apprentice Finale and...  2009        11   \n",
       "4      \"My persona will never be that of a wallflower...  2009      1375   \n",
       "...                                                  ...   ...       ...   \n",
       "43347  Joe Biden was a TOTAL FAILURE in Government. H...  2020     23402   \n",
       "43348  Will be interviewed on @ seanhannity tonight a...  2020     11810   \n",
       "43349                         pic.twitter.com/3lm1spbU8X  2020      4959   \n",
       "43350                         pic.twitter.com/vpCE5MadUz  2020      4627   \n",
       "43351                         pic.twitter.com/VLlc0BHW41  2020      3951   \n",
       "\n",
       "       favorites                                          cleantext  \n",
       "0            917  sure tune watch donald trump late night david ...  \n",
       "1            267  donald trump appearing view tomorrow morning d...  \n",
       "2             19  donald trump read top ten financial tip late s...  \n",
       "3             26  new blog post celebrity apprentice finale less...  \n",
       "4           1945  persona never wallflower rather build wall cli...  \n",
       "...          ...                                                ...  \n",
       "43347     116377  joe biden total failure government bungled eve...  \n",
       "43348      56659              interviewed seanhannity tonight enjoy  \n",
       "43349      19344                                                     \n",
       "43350      17022                                                     \n",
       "43351      14344                                                     \n",
       "\n",
       "[43352 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = []\n",
    "for item in tqdm(data[\"date\"]):\n",
    "    year = parse(item).year\n",
    "    dates+=[year]\n",
    "data['date']=dates\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Create Corpus <a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sure tune watch donald trump late night david letterman present top ten list tonight',\n",
       " 'donald trump appearing view tomorrow morning discus celebrity apprentice new book think like champion',\n",
       " 'donald trump read top ten financial tip late show david letterman funny',\n",
       " 'new blog post celebrity apprentice finale lesson learned along way',\n",
       " 'persona never wallflower rather build wall cling donald trump']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = list(data.cleantext)\n",
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Vectorize Word-Doc Relations <a class=\"anchor\" id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaa',\n",
       " 'aaafivediamond',\n",
       " 'aaanews',\n",
       " 'aacrowellt',\n",
       " 'aaron',\n",
       " 'aaronmcallorum',\n",
       " 'aaszkler',\n",
       " 'ab',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abbas',\n",
       " 'abbott',\n",
       " 'abbydnyc',\n",
       " 'abc']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(binary=True, min_df=2, max_df=0.9)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "vocabulary = vectorizer.get_feature_names()\n",
    "vocabulary[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Get Occurrence and Co-Occurrence matrix <a class=\"anchor\" id=\"6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occurrence_matrix = np.array(X.toarray())\n",
    "occurrence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<14436x14436 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2543244 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform occ_matrix to sparse for optimization\n",
    "sparse_W = csr_matrix(occurrence_matrix)\n",
    "co_occurrence_matrix = sparse_W.transpose().dot(sparse_W)\n",
    "co_occurrence_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43352"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of documents\n",
    "N = occurrence_matrix.shape[0]\n",
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Function to Find Index of element in np array <a class=\"anchor\" id=\"7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_index(arr, val):\n",
    "    base = np.array(arr)\n",
    "    index = np.where(base == val)\n",
    "    if len(index[0]) == 0:\n",
    "        sys.exit(\"Word you entered wasn't found in any document\")\n",
    "    return index[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Calculate number of documents containing specific word <a class=\"anchor\" id=\"8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14436/14436 [01:23<00:00, 172.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaa',\n",
       " 'aaafivediamond',\n",
       " 'aaanews',\n",
       " 'aacrowellt',\n",
       " 'aaron',\n",
       " 'aaronmcallorum',\n",
       " 'aaszkler',\n",
       " 'ab',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abbas',\n",
       " 'abbott',\n",
       " 'abbydnyc',\n",
       " 'abc',\n",
       " 'abcfamily',\n",
       " 'abcinsc',\n",
       " 'abcnews',\n",
       " 'abcpolitics',\n",
       " 'abcsharktank',\n",
       " 'abcworldnews',\n",
       " 'abdel',\n",
       " 'abdul',\n",
       " 'abdullah',\n",
       " 'abe',\n",
       " 'abedin',\n",
       " 'abedini',\n",
       " 'aberdeen',\n",
       " 'aberdeencc',\n",
       " 'aberdeenshire']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occurrence_count = {}  # number of documents containing a word\n",
    "\n",
    "# calculate number of documents containing a word\n",
    "for w in tqdm(vocabulary):\n",
    "    i = find_index(vocabulary, w)\n",
    "    occurrence_count[w] = np.sum(occurrence_matrix[:, i])\n",
    "[x for i, x in enumerate(occurrence_count) if i < 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Functions to produce Mutual Information <a class=\"anchor\" id=\"9\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# calculate probabilities\n",
    "def p(w1, present1, w2=None, present2=None, p_co=None):\n",
    "\n",
    "    p_w1 = (occurrence_count[w1] + 0.5) / (N + 1)\n",
    "\n",
    "    # if it's singular probability\n",
    "    if w2 is None:\n",
    "        if present1:\n",
    "            return p_w1\n",
    "        else:\n",
    "            return 1 - p_w1\n",
    "\n",
    "    p_w2 = (occurrence_count[w2] + 0.5) / (N + 1)\n",
    "\n",
    "    if present1 and present2:  # p(w1 = 1, w2 = 1)\n",
    "        return p_co\n",
    "    elif present1 and not present2:  # p(w1 = 1, w2 = 0)\n",
    "        return p_w1 - p_co\n",
    "    elif not present1 and present2:  # p(w1 = 0, w2 = 1)\n",
    "        return p_w2 - p_co\n",
    "    elif not present1 and not present2:  # p(w1 = 0, w2 = 0)\n",
    "        return 1 - (p_co + (p_w1 - p_co) + (p_w2 - p_co))\n",
    "\n",
    "\n",
    "def mi(w1, w2, p_co):\n",
    "    summation = 0\n",
    "    for u in [False, True]:\n",
    "        for v in [False, True]:\n",
    "            numerator = p(w1, u, w2, v, p_co)\n",
    "            denominator = p(w1, u) * p(w2, v)\n",
    "            summation += numerator * np.log2(numerator / denominator)\n",
    "\n",
    "    return summation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Calculate MI score for all pairs of words <a class=\"anchor\" id=\"10\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17fddbee48bb4a5ea0717fa8e1eca560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2543244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0010755 , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.00392653, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.00075952, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.00255143, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.00197699,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.0013826 ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = list(combinations(vocabulary, 2))\n",
    "mi_matrix = np.zeros(shape=(len(vocabulary), len(vocabulary)))  # matrix to save MI score of words\n",
    "sorted_matrix = co_occurrence_matrix.sorted_indices()\n",
    "cx = sorted_matrix.tocoo()\n",
    "for i, j, v in tzip(cx.row, cx.col, cx.data):  # TQDM lib used for exec time estimation\n",
    "    p_co = (v + 0.25) / (N + 1)\n",
    "    mi_value = mi(vocabulary[i], vocabulary[j], p_co)\n",
    "    mi_matrix[i, j] = mi_value\n",
    "mi_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 Syntagmtatic Related words <a class=\"anchor\" id=\"11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(392, 0.00054),\n",
       " (1237, 0.02861),\n",
       " (2143, 0.00082),\n",
       " (3293, 0.0006),\n",
       " (4762, 0.00078),\n",
       " (5781, 0.00061),\n",
       " (5943, 0.00224),\n",
       " (6704, 0.01131),\n",
       " (11780, 0.00756),\n",
       " (11912, 0.00099),\n",
       " (12500, 0.00081),\n",
       " (13441, 0.00129),\n",
       " (13442, 0.00071)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def syntagmatic(word):\n",
    "    idx = find_index(vocabulary, word)\n",
    "    sim = mi_matrix[idx, :]\n",
    "    # print(sim)\n",
    "    # ind = np.argpartition(sim, -20)[-20:]  # get top 10 MI scores indexes\n",
    "    ind = [idx for idx, val in enumerate(sim) if val > 0.0005]\n",
    "    count = 1\n",
    "    sims = []\n",
    "    for j in ind:\n",
    "        # print(count, ':', vocabulary[j], \"-->\", round(sim[j], 5))\n",
    "        sims.append((j, round(sim[j], 5)))\n",
    "        count += 1\n",
    "    return sims\n",
    "\n",
    "syntagmatic(\"biden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(297, 0.00065),\n",
       " (803, 0.00101),\n",
       " (1267, 0.00065),\n",
       " (1934, 0.00055),\n",
       " (2180, 0.0006),\n",
       " (3139, 0.00475),\n",
       " (3818, 0.00078),\n",
       " (5849, 0.00074),\n",
       " (5865, 0.00069),\n",
       " (6121, 0.00059),\n",
       " (6427, 0.06603),\n",
       " (6429, 0.00224),\n",
       " (6430, 0.00287),\n",
       " (6465, 0.00122),\n",
       " (6985, 0.00155),\n",
       " (7391, 0.00061),\n",
       " (8644, 0.00051),\n",
       " (8856, 0.00623),\n",
       " (8859, 0.00153),\n",
       " (8906, 0.00201),\n",
       " (8982, 0.00153),\n",
       " (9277, 0.00079),\n",
       " (9996, 0.00077),\n",
       " (10269, 0.00159),\n",
       " (11025, 0.00071),\n",
       " (11121, 0.00358),\n",
       " (12520, 0.0014),\n",
       " (12541, 0.00054),\n",
       " (12731, 0.00061),\n",
       " (12897, 0.00095),\n",
       " (13539, 0.00074),\n",
       " (14020, 0.0009),\n",
       " (14256, 0.0006)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntagmatic(\"iran\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12 Save Output <a class=\"anchor\" id=\"12\"></a>\n",
    "#### Make directory available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "output_dir = Path('./Syntagmatic')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print Nodes and Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14436/14436 [00:59<00:00, 243.94it/s]\n"
     ]
    }
   ],
   "source": [
    "def print_nodes():\n",
    "    with open( \"./Syntagmatic/nodes.csv\", \"w\", newline='') as csv_out:\n",
    "        writer = csv.writer(csv_out, delimiter=',')\n",
    "        fields = [\"Id\", \"Label\"]\n",
    "        writer.writerow(fields)\n",
    "        for w in tqdm(vocabulary):\n",
    "            writer.writerow([find_index(vocabulary, w), w])\n",
    "print_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14436/14436 [04:53<00:00, 49.16it/s]\n"
     ]
    }
   ],
   "source": [
    "def print_edges():\n",
    "    with open(\"./Syntagmatic/edges.csv\", \"w\", newline='') as csv_out:\n",
    "        writer = csv.writer(csv_out, delimiter=',')\n",
    "        fields = [\"Source\", \"Target\", \"Type\", \"Weight\"]\n",
    "        writer.writerow(fields)\n",
    "        for word in tqdm(vocabulary):\n",
    "            answers = syntagmatic(word)\n",
    "            rows = []\n",
    "            for answer in answers:\n",
    "                rows.append([find_index(vocabulary, word), answer[0], \"Undirected\", answer[1]])\n",
    "            writer.writerows(rows)\n",
    "print_edges()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (IR-prj)",
   "language": "python",
   "name": "pycharm-a75a7163"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}